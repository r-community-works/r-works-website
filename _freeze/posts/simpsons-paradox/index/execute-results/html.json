{
  "hash": "6f0a9b512f5dc7570cacdf2e3a0fe08e",
  "result": {
    "markdown": "---\ntitle: \"Simpson's Paradox in a Logistic Regression\"\nauthor: \"Nina Zumel\"\ndate: 2025-02-07\nhtml:\n    code-fold: true\n    code-summary: \"Show the code\"\neditor: source\ndescription: \"In this post, I show an example of Simpson's paradox in a logistic regression model of synthetic clinical trial data.\"\nimage: \"sp.png\"\nimage-alt: \"Plot showing unbalanced treatment group sizes\"\ncategories: \"\"\n---\n\n\n[Simpson's paradox](https://en.wikipedia.org/wiki/Simpson's_paradox) is when a trend that is present in various groups of data seems to disappear or even reverse when those groups are combined. One sees examples of this often in things like  medical trials, and the phenomenon is generally due to one or more unmodelled confounding variables, or perhaps differing causal assumptions.\n\nAs part of a project I was working on, I wanted an example beyond a simple linear regression where one of the model coefficients had a clearly incorrect sign. There are several reasons why unexpected signs might happen: separation or quasi separation of the data being the obvious ones. But Simpson's paradox is another possible cause. The original project ended up not needing the example, but since I had it, I thought I'd write it up, \nsince I've never seen Simpson's paradox presented in quite this way before.\n\n## Synthetic Example: Weight Loss Trial\n\nThis is a problem statement where we would expect the coefficients of a logistic regression to be non-negative (except the intercept).\n\nConsider a trial that tests the efficacy of a specific eating regimen (let's say 16/8 intermittent fasting, which we'll call `ifasting`) and a specific exercise regimen (a brisk 30 minute walk every day, which we'll \njust call `exercise`). The goal (\"success\") is to lose at least five pounds by the end of the trial period. We've set up three treatment groups, as follows:\n\n* 200 subjects try exercise alone\n* 300 subjects try ifasting alone\n* 300 subjects try ifasting plus exercise\n\nPrior to the trial, all the subjects led fairly sedentary lifestyles, and weren't dieting in any formal way.\n\nFor these subjects, one might reasonably expect that neither exercise nor ifasting would be *less* successful for losing weight than doing nothing. One would also reasonably expect that ifasting plus exercise should do no worse than doing either one alone. Therefore, modeling the results of such an experiment as a logistic regression\nshould lead to a model where the coefficients $\\beta_{ifasting}$ and $\\beta_{exercise}$ are both non-negative, as any treatment should increase (or at least, not decrease) the odds that the subject loses weight. \n\nLet's show an example where our expectations aren't met. The easiest way to do that is to generate a dataset that has Simpson's paradox hidden within it.\n\nFirst, let's load the packages we need.\n\n\n::: {.cell warnings='false'}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nlibrary(poorman) # or dplyr\nlibrary(ggplot2)\nlibrary(kableExtra)\nlibrary(WVPlots)\n```\n:::\n\n\nHere's a function that will generate a specific subset of data, as needed.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ifasting: 1 if this group fasted, else 0\n# exercise: 1 if this group exercised, else 0\n# total: total number of subjects in this group\n# successes:  number of subjects who successfully lost weight\n# label: label for the group.\ngenerate_samples = function(ifasting, exercise, total, successes, label) {\n  failures = total-successes\n  data.frame(ifasting = ifasting,\n             exercise = exercise,\n             success = c(rep(1, successes), rep(0, failures)),\n             label=label)\n}\n```\n:::\n\n\n\n## Hidden, Unmodelled Population Effects\n\nNow suppose that, unbeknownst to the researchers, there are two sub populations among the subjects. These two sub populations respond differently to the exercise and intermittent fasting regimes. So we will generate our synthetic data by population.\n\n### Population A\n\nThe first population, Population A, responds quite well to intermittent fasting. Let's create just this population. This next block of code generates population A, prepares the data for plotting, and plots it.\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\npopA = data.table::rbindlist(list(\n  generate_samples(ifasting=0, exercise=1, total=100, successes=2, \"Population A\"),\n  generate_samples(ifasting=1, exercise=0, total=200, successes=160, \"Population A\"),\n  generate_samples(ifasting=1, exercise=1, total=100, successes=90, \"Population A\")\n))\n\n#| code-fold: true\n#| code-summary: \"Show the code\"\npopA$treatment = with(popA, ifelse(ifasting, ifelse(exercise, 'both', 'ifast alone'),\n                                   ifelse(exercise, 'exercise alone', 'none')))\npopA$treatment = factor(popA$treatment,\n                            levels = c('none', 'exercise alone', 'ifast alone', 'both'))\npopA$outcome = factor(with(popA, ifelse(success==1, \"success\", \"failure\")),\n                      levels = c('success', 'failure'))\n\npvals = c(success='darkblue', failure='gray')\n\nggplot(popA, aes(x=treatment, color=outcome, fill=outcome)) + \n  geom_bar() +\n  scale_fill_manual(values=pvals) + \n  scale_color_manual(values=pvals) +\n  ggtitle(\"Outcomes for population A\") + \n  theme(legend.position=\"bottom\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nIf we look at the success rates, we will see that (as expected) subjects who both exercise and practice intermittent fasting lose weight more successfully than subjects who do one or the other alone.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\ndf1 = popA |>\n  group_by(treatment) |>\n  summarize(success_rate=mean(success)) |>\n  ungroup() \n\ndf2 = popA |>\n  summarize(success_rate = mean(success)) |>\n  mutate(treatment = \"overall\") \n\nrbind(df1, df2) |>\n  knitr::kable(digits=3, caption = \"Success rates, Population A\")\n```\n\n::: {.cell-output-display}\nTable: Success rates, Population A\n\n|treatment      | success_rate|\n|:--------------|------------:|\n|exercise alone |         0.02|\n|ifast alone    |         0.80|\n|both           |         0.90|\n|overall        |         0.63|\n:::\n:::\n\n\n### Population B\n\nThere is also another population, Population B, that has what you might call a \"stickier\" metabolism.\nFor them, intermittent fasting is not quite as effective.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\npopB = data.table::rbindlist(list(\n  generate_samples(ifasting=0, exercise=1, total=100, successes=1, \"Population B\"),\n  generate_samples(ifasting=1, exercise=0, total=100, successes=40, \"Population B\"),\n  generate_samples(ifasting=1, exercise=1, total=200, successes=100, \"Population B\")\n))\n\n\n#| code-fold: true\n#| code-summary: \"Show the code\"\npopB$treatment = with(popB, ifelse(ifasting, ifelse(exercise, 'both', 'ifast alone'),\n                                   ifelse(exercise, 'exercise alone', 'none')))\npopB$treatment = factor(popB$treatment,\n                            levels = c('none', 'exercise alone', 'ifast alone', 'both'))\npopB$outcome = factor(with(popB, ifelse(success==1, \"success\", \"failure\")),\n                      levels = c('success', 'failure'))\n\n\n\npvals = c(success='darkblue', failure='gray')\n\nggplot(popB, aes(x=treatment, color=outcome, fill=outcome)) + \n  geom_bar() +\n  scale_fill_manual(values=pvals) + \n  scale_color_manual(values=pvals) +\n  ggtitle(\"Outcomes for population B\") + \n  theme(legend.position=\"bottom\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nAgain, subjects who both exercise and practice intermittent fasting are the most successful, but overall, success rates in population B are not as good as in population A.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\ndf1 = popB |>\n  group_by(treatment) |>\n  summarize(success_rate=mean(success)) |>\n  ungroup() \n\ndf2 = popB |>\n  summarize(success_rate = mean(success)) |>\n  mutate(treatment = \"overall\") \n\nrbind(df1, df2) |>\n  knitr::kable(digits=3, caption = \"Success rates, Population B\")\n```\n\n::: {.cell-output-display}\nTable: Success rates, Population B\n\n|treatment      | success_rate|\n|:--------------|------------:|\n|exercise alone |        0.010|\n|ifast alone    |        0.400|\n|both           |        0.500|\n|overall        |        0.352|\n:::\n:::\n\n\nOne of the things to notice about this experimental design is that, even before taking the hidden population types into account, the treatment groups are not balanced. We saw this in the initial statement above (200 subjects try exercise alone; 300 subjects try ifasting alone; 300 subjects try ifasting plus exercise). This is often what happens in experimental trials with human subjects. as subjects may drop out for one reason or another. Unbalanced treatment groups tend to be the norm in retrospective analyses, as well.\n\nThis imbalance will be even more pronounced when we account for the hidden population types, as well.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nbothpops = rbind(popA, popB)\npalette = c('Population A' = '#1b9e77', 'Population B' = '#d95f02')\nggplot(bothpops, aes(x=treatment, color=label, fill=label)) + \n  geom_bar() + \n  scale_fill_manual(values=palette) + \n  scale_color_manual(values=palette) +\n  ggtitle(\"Treatment Group Sizes, with population labels\") + \n  theme(legend.position=\"bottom\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nThis population imbalance is part of what can cause Simpson's paradox.\n\n## Modelling\n\nNow let's fit a logistic regression model to try to infer the effects of the various treatments on weight loss. We'll do it on the whole population first, since that was the original task.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\ntab_coeff = function(model, caption) {\n  coeff = summary(model)$coefficients[, c(1, 4)] |>\n    as.data.frame()\n\n  colnames(coeff) = c('Estimate', 'pval')\n\n  # using cell_spec below breaks the digits setting\n  # (because of course it does) so round the numbers first.\n  coeff = coeff |>\n    mutate(Estimate = as.numeric(formatC(Estimate, format=\"f\", digits=3)),\n           pval = as.numeric(format(pval, format=\"g\", digits=3)))\n\n  coeff = coeff |>\n    mutate(Estimate = cell_spec(Estimate, color=ifelse(Estimate < 0, \"red\", \"black\")),\n           pval = cell_spec(pval, color=ifelse(pval < 0.05, \"darkblue\", \"darkgray\")))\n\n  knitr::kable(coeff, caption=caption)\n\n}\n\nbothpops = rbind(popA, popB)\nmAll = glm(success ~ ifasting + exercise, data=bothpops, family=binomial)\n\ntab_coeff(mAll, \"Model coefficients, whole population\")\n```\n\n::: {.cell-output-display}\nTable: Model coefficients, whole population\n\n|            |Estimate                                                  |pval                                                            |\n|:-----------|:---------------------------------------------------------|:---------------------------------------------------------------|\n|(Intercept) |<span style=\"     color: red !important;\" >-4.038</span>  |<span style=\"     color: darkblue !important;\" >2.72e-11</span> |\n|ifasting    |<span style=\"     color: black !important;\" >4.731</span> |<span style=\"     color: darkblue !important;\" >1.6e-15</span>  |\n|exercise    |<span style=\"     color: red !important;\" >-0.147</span>  |<span style=\"     color: darkgray !important;\" >0.392</span>    |\n:::\n:::\n\n\nIntermittent fasting has a positive coefficient, meaning intermittent fasting is positively correlated with weight loss success. But exercise has a *negative* coefficient, implying the exercise is negatively correlated with weight loss, and that doing both together will be *less* successful than intermittent fasting alone!\n\nAnd indeed, if we look at the raw summaries, we'll see that the data bears these inferences out.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\ndf1 = bothpops |>\n  group_by(treatment) |>\n  summarize(success_rate=mean(success)) |>\n  ungroup() \n\ndf2 = bothpops |>\n  summarize(success_rate = mean(success)) |>\n  mutate(treatment = \"overall\") \n\nrbind(df1, df2) |>\n  knitr::kable(digits=3, caption = \"Success rates, entire population\")\n```\n\n::: {.cell-output-display}\nTable: Success rates, entire population\n\n|treatment      | success_rate|\n|:--------------|------------:|\n|exercise alone |        0.015|\n|ifast alone    |        0.667|\n|both           |        0.633|\n|overall        |        0.491|\n:::\n:::\n\n\nThis is an example of how Simpson’s paradox might manifest itself in a logistic regression model, and it’s due to the unmodelled confounding variable, population type. This, plus some bad luck in the relative sizes of the treatment groups with respect to population type, lead to the above, counter intuitive, results. \n\nNote that we have reported p-values, and in this case the coefficient for exercise is insignificant (to $p = 0.05$), implying that exercise may not have any notable effect on weight loss. However, we may still see coefficients with counter intuitive signs in arbitrarily large populations, which may then appear significant.\n\n### Taking the Hidden Confounder into Account\n\nAs you might expect, if we are able to identify the confounding variable and account for it, then we can eliminate the paradoxical negative coefficients. To see this, let's first model the populations separately and look at the model coefficients.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nmA = glm(success ~ ifasting + exercise, data=popA, family=binomial)\n\ntab_coeff(mA, \"Model coefficients, Population A\")\n```\n\n::: {.cell-output-display}\nTable: Model coefficients, Population A\n\n|            |Estimate                                                  |pval                                                            |\n|:-----------|:---------------------------------------------------------|:---------------------------------------------------------------|\n|(Intercept) |<span style=\"     color: red !important;\" >-4.703</span>  |<span style=\"     color: darkblue !important;\" >5.82e-09</span> |\n|ifasting    |<span style=\"     color: black !important;\" >6.089</span> |<span style=\"     color: darkblue !important;\" >1.12e-14</span> |\n|exercise    |<span style=\"     color: black !important;\" >0.811</span> |<span style=\"     color: darkblue !important;\" >0.0316</span>   |\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nmB = glm(success ~ ifasting + exercise, data=popB, family=binomial)\n\ntab_coeff(mB, \"Model coefficients, Population B\")\n```\n\n::: {.cell-output-display}\nTable: Model coefficients, Population B\n\n|            |Estimate                                                  |pval                                                            |\n|:-----------|:---------------------------------------------------------|:---------------------------------------------------------------|\n|(Intercept) |<span style=\"     color: red !important;\" >-5.001</span>  |<span style=\"     color: darkblue !important;\" >1.36e-06</span> |\n|ifasting    |<span style=\"     color: black !important;\" >4.595</span> |<span style=\"     color: darkblue !important;\" >5.97e-06</span> |\n|exercise    |<span style=\"     color: black !important;\" >0.405</span> |<span style=\"     color: darkgray !important;\" >0.103</span>    |\n:::\n:::\n\n\nIn both cases, both intermittent fasting and exercise have positive coefficients, indicating that both activities correlate positively with weight loss.\n\nWe can also model the entire population, including the population label as a variable.\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nmAllplus = glm(success ~ ifasting + exercise + label, data=bothpops, family=binomial)\n\n#| code-fold: true\n#| code-summary: \"Show the code\"\ntab_coeff(mAllplus, \"Model coefficients, whole population with population labels\")\n```\n\n::: {.cell-output-display}\nTable: Model coefficients, whole population with population labels\n\n|                  |Estimate                                                  |pval                                                            |\n|:-----------------|:---------------------------------------------------------|:---------------------------------------------------------------|\n|(Intercept)       |<span style=\"     color: red !important;\" >-4.143</span>  |<span style=\"     color: darkblue !important;\" >1.69e-11</span> |\n|ifasting          |<span style=\"     color: black !important;\" >5.584</span> |<span style=\"     color: darkblue !important;\" >1.15e-19</span> |\n|exercise          |<span style=\"     color: black !important;\" >0.523</span> |<span style=\"     color: darkblue !important;\" >0.0102</span>   |\n|labelPopulation B |<span style=\"     color: red !important;\" >-1.917</span>  |<span style=\"     color: darkblue !important;\" >7.65e-20</span> |\n:::\n:::\n\n\nAs expected, both `ifasting` and `exercise` now have positive (and significant, to $p=0.05$) coefficients, indicating that both actions increase the probability of weight loss, and doing them both increases it even more.\n\nThe model also correctly identifies that subjects of population type B have a (significantly) lower success rate than subjects from Population A.\n\n\n## Conclusion\n\nSimpson's paradox is a case where model inference seems to contradict domain knowledge. Usually it is merely a symptom of some combination of omitted variable bias, unbalanced studies, or wrong causal specification (or perhaps no such specification). If you take care to look for the this effect, it can in fact give clues towards a better analysis.\n\n*Nina Zumel is a data scientist based in San Francisco, with 20+ years of experience in machine learning, statistics, and analytics. She is the co-founder of the data science consulting firm Win-Vector LLC, and (with John Mount) the co-author of Practical Data Science with R, now in its second edition.*",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}